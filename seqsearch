#!/usr/bin/env python3
#
# taxonomically classify a novel nucleotide sequence
#

import argparse
import csv
import re
import pandas as pd
import json
import os
import sys
import subprocess
import glob
#
# parse ARGS
#
parser = argparse.ArgumentParser(description="")
parser.add_argument('-verbose',help="print details during run",action=argparse.BooleanOptionalAction)
parser.add_argument('-indir',help="directory for fasta files with NUCLEOTIDE seqeunces to classify",default="seq_in")
parser.add_argument('-outdir',help="output directory for tax_results.json",default="tax_out")
parser.add_argument('-json',help="output json filename",default="tax_results.json")
parser.add_argument('-html',help="output  html base filename",default="tax_results")
parser.add_argument('-blastdb',help="input blast base filename",default="./blast/ICTV_VMR_b")
args = parser.parse_args()

print("Hello World")
print("IN_DIR: ", args.indir)
print("OUT_DIR:", args.outdir)
print("OUT_JSON:", args.json)
print("OUT_HTML:", args.html)

#
# read version number
#
with open("version_git.txt") as verfile:
    git_version = verfile.readline().strip()
print("VERSION:", git_version )



# "input_file"             : "test12.fa",
        #     "input_seq"              : "test_seq_1",
        #     "status"                 : "CLASSIFIED",
        #     "classification_rank"    : "species",
        #     "classification_lineage" : {"realm":"HelloRealm", "family":"BigFamily", "genus":"WorldGenus", "species":"WorldGenus specius"},
        #     "blast_html"             : args.html+"_1.html",
        #     "blast_csv"              : args.html+"_1.csv",
        # }
        # ,
        # "html_dict": {
        #     "input_file"             : "test12.fa",
        #     "input_seq"              : "test_seq_2",
        #     "status"                 : "CLASSIFIED",
        #     "classification_rank"    : "genus",
        #     "classification_lineage" : {"realm":"HelloRealm", "family":"BigFamily", "genus":"CountryGenus"},
        #     "message"                : "Homologous to species within the genus, but not close enough to classify within an existing species",
        #     "blast_html"             : args.html+"_2.html",
        #     "blast_csv"              : args.html+"_2.csv",
        # } 
# hello world data dictionary
#
json_hits = {
    "program_name": os.path.basename(sys.argv[0]),
    "version"  : git_version,
    "database_name": args.blastdb,
    "database_title": "",
    "errors": "",
    "input_dir": args.indir,
    "results":[]          
}


#
# bogus "hello world" data
#


# for eden: get list of fasta files in input directory (.fa/.fna.fasta) 
if args.verbose:
    print("Files in input directory: ", os.listdir(args.indir))
# get list of fasta files
fasta_files = []
for  infilename in os.listdir(args.indir):
    if infilename.endswith(".fa") or infilename.endswith(".fna") or infilename.endswith(".fasta"):
            fasta_files.append (infilename)
print("FASTA files found: ", fasta_files)

# iterate over fasta files
for infilename in fasta_files:
    # read in fasta file
    fasta_file_path = os.path.join(args.indir, infilename)
    blastasn_output_filepath= os.path.join(args.outdir, infilename + ".asn")
    blastcsv_output_filepath= os.path.join(args.outdir, infilename + ".csv")
    blasthtml_output_filepath= os.path.join(args.outdir, infilename + ".html")

    #blast output format commands.

    blastasn_cmd = ["blastn", "-db", args.blastdb , "-query", fasta_file_path , "-out", blastasn_output_filepath, "-outfmt", "11"]
    blastcsv_cmd = ["blast_formatter", "-archive", blastasn_output_filepath , "-out", blastcsv_output_filepath, "-outfmt", "10"]
    blasthtml_cmd = ["blast_formatter", "-archive", blastasn_output_filepath,  "-out", blasthtml_output_filepath, "-html" ]
    print("ASN Format Command:", " ".join(blastasn_cmd), "\n", "CSV Format Command:", " ".join(blastcsv_cmd), "\n", "HTML Format Command:", " ".join(blasthtml_cmd))

    db_output_asn = subprocess.run(blastasn_cmd, capture_output=True, text=True)
    print("Blast .asn output files:", blastasn_output_filepath)
    db_output_csv = subprocess.run(blastcsv_cmd, capture_output=True, text=True)
    print("Blast .csv output files:", blastcsv_output_filepath)
    db_output_html = subprocess.run(blasthtml_cmd, capture_output=True, text=True)
    print("Blast .html output files:", blasthtml_output_filepath)

   
    # read in csv file and set headers to extract data
    for file in [blastcsv_output_filepath]:
         try:
            raw_data = pd.read_csv(file)
        # Process the file only if it's successfully read
            #df is df for the blast csv file
            #df2 is df for the processed_accessions_b.tsv file
            df = pd.read_csv(file, header=0, names=["qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore"])
            df2= pd.read_csv("processed_accessions_b.tsv", sep="\t", header=0)
            for index, row in df.iterrows():
                print(row)
                hit= {}           # append to hit
                hit["blast_csv"] = blastcsv_output_filepath
                hit["input_file"] = infilename
                hit["input_seq"] = infilename.split(".")[0]
                hit["sseqid"]= row["sseqid"]
                hit["evalue"]= row["evalue"]
                hit["bitscore"]= row["bitscore"]
                hit["qseqid"]= row["qseqid"]
                hit["blast_html"] = blasthtml_output_filepath
                hit["status"] = "HITS"
                #establishing dict in hit dict
                hit["sseqid_lineage"]= {}
                #splitting the sseqid row into two parts
                if hit["sseqid"]:
                    delimiter = r"[#,]"
                    hit["sseqid_accession"]= re.split(delimiter, hit["sseqid"])[0]
                    hit["sseqid_species_name"]= re.split(delimiter, hit["sseqid"])[1]
                    hit["sseqid_species_name"] = re.sub("_", " ", hit["sseqid_species_name"])
                    hit["sseqid"]= hit["sseqid_accession"]
                #splitting the qseqid row into two parts to just show the qseqid without everything after the first #
                delimiter= r"[#]"
                hit["qseqid"]= re.split(delimiter, hit["qseqid"])[0]

                #reading into the processed_accessions_b.tsv file
                
                for index, row in df2.iterrows():
                     split_seqaccession_at_dot = re.split(r"\.", hit["sseqid_accession"])
                     sseqid_without_dot= split_seqaccession_at_dot[0].strip()
                     print("Sseqid without dot: ", sseqid_without_dot)
                     hit["accession"]= row ["Accession"]
                     if str(row["Accession"]).strip== str(sseqid_without_dot).strip():
                         print("Found a match: ",["Accession"])
                         hit["sseqid_lineage"]["species"]= ["Species"]
                         hit["sseqid_lineage"]["genus"]= ["Genus"]

                     #remove the second part of the sseqid_accession
                     
                    
                    #  delimiter = r"[ ]"
                    #  hit["sseqid_lineage"]["genus"]= re.split(delimiter, hit["sseqid_species_name"])[0]
                     
                    #  hit["sseqid_lineage"]["species"]= re.split(delimiter, row["Species"])
                    #  if 
                    #      print("THIS IS Genus: ", hit["sseqid_lineage"]["genus"])
                        #  hit["sseqid_lineage"]["species"]= df.loc["Species"]

                    
                     #outputting accessions with their segment number by checking if the accession index is greater than 1
                    #  if row["Accession_Index"] > 1:
                    #      hit["sseqid_lineage"]["seqnum"] = row["Segment_Name"]
                         
                    #  else:
                    #      hit["sseqid_lineage"]["seqnum"] = "Seq1"
                    #  print("Hit: ", hit)
            #adds results to json dict
                     json_hits["results"].append(hit)
                     break
         except pd.errors.EmptyDataError:
            print(file, "is empty and has been skipped.", "status: NO_HITS")


        


            
            
            
    
    
            


#    """  print("Reading fasta file: ", fasta_file_path)
#     with open(fasta_file_path, 'r') as f:
#         fasta_data = f.read()
#         # parse fasta data
#         seqs = fasta_data.split('>')[1:]  # split on '>' and ignore the first element
#         for seq in seqs:
#             header, sequence = seq.split('\n', 1)
#             sequence = sequence.replace('\n', '')
#             print("Header: ", header)
#             print("Sequence: ", sequence) """

#
# write output/results
#

# Ensure the output directory exists
os.makedirs(args.outdir, exist_ok=True)

# json job output/summary
json_outpath=os.path.join(args.outdir, args.json)
with open(json_outpath, "w") as outfile:
    json.dump(obj=json_hits, fp=outfile, indent=4)
print("Wrote: ", json_outpath)
outfile.close()



exit(0)


